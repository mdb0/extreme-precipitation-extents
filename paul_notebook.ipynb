{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cf49c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from statsmodels.gam.api import GLMGam, BSplines\n",
    "from statsmodels.genmod.families import Gamma as GammaFamily\n",
    "from statsmodels.genmod.families import Binomial\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6ca0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./weather_data_filled_1950_2023.csv.gz\", \n",
    "                compression='gzip', \n",
    "                sep=',',  \n",
    "                encoding='utf-8', \n",
    "                low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc25b2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "NUM_POSTE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LAT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LON",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ALTI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TNTXM",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day_of_year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "67745269-030b-47ed-ab9a-a4ef9a8151c8",
       "rows": [
        [
         "count",
         "5650137.0",
         "5650137.0",
         "5650137.0",
         "5650137.0",
         "5641423.0",
         "5650137.0",
         "5650137.0",
         "5650137.0"
        ],
        [
         "mean",
         "33092040.440164194",
         "47.429344722961226",
         "1.699505034504827",
         "145.05224528184007",
         "1.9561109847639506",
         "11.39959962856973",
         "183.1340903769236",
         "1989.0832232917537"
        ],
        [
         "std",
         "9268498.75039815",
         "0.5888689558356694",
         "0.7028758111056366",
         "60.95974703251492",
         "4.374758827707137",
         "6.568808129551034",
         "105.4492104472831",
         "20.243688467966198"
        ],
        [
         "min",
         "18003002.0",
         "46.425333",
         "0.107833",
         "31.0",
         "0.0",
         "-20.3",
         "1.0",
         "1950.0"
        ],
        [
         "25%",
         "28070001.0",
         "46.971833",
         "1.178333",
         "107.0",
         "0.0",
         "6.6",
         "92.0",
         "1973.0"
        ],
        [
         "50%",
         "36139001.0",
         "47.336167",
         "1.692333",
         "132.0",
         "0.0",
         "11.46892997532375",
         "183.0",
         "1992.0"
        ],
        [
         "75%",
         "41050002.0",
         "47.886667",
         "2.243833",
         "169.0",
         "1.9",
         "16.5",
         "274.0",
         "2006.0"
        ],
        [
         "max",
         "45340002.0",
         "48.8015",
         "3.053333",
         "462.0",
         "180.8",
         "32.8",
         "366.0",
         "2023.0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM_POSTE</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>ALTI</th>\n",
       "      <th>RR</th>\n",
       "      <th>TNTXM</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.650137e+06</td>\n",
       "      <td>5.650137e+06</td>\n",
       "      <td>5.650137e+06</td>\n",
       "      <td>5.650137e+06</td>\n",
       "      <td>5.641423e+06</td>\n",
       "      <td>5.650137e+06</td>\n",
       "      <td>5.650137e+06</td>\n",
       "      <td>5.650137e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.309204e+07</td>\n",
       "      <td>4.742934e+01</td>\n",
       "      <td>1.699505e+00</td>\n",
       "      <td>1.450522e+02</td>\n",
       "      <td>1.956111e+00</td>\n",
       "      <td>1.139960e+01</td>\n",
       "      <td>1.831341e+02</td>\n",
       "      <td>1.989083e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.268499e+06</td>\n",
       "      <td>5.888690e-01</td>\n",
       "      <td>7.028758e-01</td>\n",
       "      <td>6.095975e+01</td>\n",
       "      <td>4.374759e+00</td>\n",
       "      <td>6.568808e+00</td>\n",
       "      <td>1.054492e+02</td>\n",
       "      <td>2.024369e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.800300e+07</td>\n",
       "      <td>4.642533e+01</td>\n",
       "      <td>1.078330e-01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.030000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.950000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.807000e+07</td>\n",
       "      <td>4.697183e+01</td>\n",
       "      <td>1.178333e+00</td>\n",
       "      <td>1.070000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.600000e+00</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>1.973000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.613900e+07</td>\n",
       "      <td>4.733617e+01</td>\n",
       "      <td>1.692333e+00</td>\n",
       "      <td>1.320000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.146893e+01</td>\n",
       "      <td>1.830000e+02</td>\n",
       "      <td>1.992000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.105000e+07</td>\n",
       "      <td>4.788667e+01</td>\n",
       "      <td>2.243833e+00</td>\n",
       "      <td>1.690000e+02</td>\n",
       "      <td>1.900000e+00</td>\n",
       "      <td>1.650000e+01</td>\n",
       "      <td>2.740000e+02</td>\n",
       "      <td>2.006000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.534000e+07</td>\n",
       "      <td>4.880150e+01</td>\n",
       "      <td>3.053333e+00</td>\n",
       "      <td>4.620000e+02</td>\n",
       "      <td>1.808000e+02</td>\n",
       "      <td>3.280000e+01</td>\n",
       "      <td>3.660000e+02</td>\n",
       "      <td>2.023000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NUM_POSTE           LAT           LON          ALTI            RR  \\\n",
       "count  5.650137e+06  5.650137e+06  5.650137e+06  5.650137e+06  5.641423e+06   \n",
       "mean   3.309204e+07  4.742934e+01  1.699505e+00  1.450522e+02  1.956111e+00   \n",
       "std    9.268499e+06  5.888690e-01  7.028758e-01  6.095975e+01  4.374759e+00   \n",
       "min    1.800300e+07  4.642533e+01  1.078330e-01  3.100000e+01  0.000000e+00   \n",
       "25%    2.807000e+07  4.697183e+01  1.178333e+00  1.070000e+02  0.000000e+00   \n",
       "50%    3.613900e+07  4.733617e+01  1.692333e+00  1.320000e+02  0.000000e+00   \n",
       "75%    4.105000e+07  4.788667e+01  2.243833e+00  1.690000e+02  1.900000e+00   \n",
       "max    4.534000e+07  4.880150e+01  3.053333e+00  4.620000e+02  1.808000e+02   \n",
       "\n",
       "              TNTXM   day_of_year          year  \n",
       "count  5.650137e+06  5.650137e+06  5.650137e+06  \n",
       "mean   1.139960e+01  1.831341e+02  1.989083e+03  \n",
       "std    6.568808e+00  1.054492e+02  2.024369e+01  \n",
       "min   -2.030000e+01  1.000000e+00  1.950000e+03  \n",
       "25%    6.600000e+00  9.200000e+01  1.973000e+03  \n",
       "50%    1.146893e+01  1.830000e+02  1.992000e+03  \n",
       "75%    1.650000e+01  2.740000e+02  2.006000e+03  \n",
       "max    3.280000e+01  3.660000e+02  2.023000e+03  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28e36a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NUM_POSTE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NOM_USUEL",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "LAT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LON",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ALTI",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "RR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TNTXM",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day_of_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_imputed",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "e95be4bb-f95f-4868-a5b9-f95ee2eb5612",
       "rows": [
        [
         "0",
         "18003002",
         "LES AIX",
         "47.216667",
         "2.55",
         "182",
         "0.0",
         "-1.1064770361756824",
         "1",
         "1950",
         "True"
        ],
        [
         "1",
         "18003002",
         "LES AIX",
         "47.216667",
         "2.55",
         "182",
         "1.6",
         "-3.019302474315791",
         "2",
         "1950",
         "True"
        ],
        [
         "2",
         "18003002",
         "LES AIX",
         "47.216667",
         "2.55",
         "182",
         "5.4",
         "3.6011411734114227",
         "3",
         "1950",
         "True"
        ],
        [
         "3",
         "18003002",
         "LES AIX",
         "47.216667",
         "2.55",
         "182",
         "2.0",
         "7.346058227320673",
         "4",
         "1950",
         "True"
        ],
        [
         "4",
         "18003002",
         "LES AIX",
         "47.216667",
         "2.55",
         "182",
         "1.9",
         "7.248366622008211",
         "5",
         "1950",
         "True"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM_POSTE</th>\n",
       "      <th>NOM_USUEL</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>ALTI</th>\n",
       "      <th>RR</th>\n",
       "      <th>TNTXM</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>year</th>\n",
       "      <th>is_imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18003002</td>\n",
       "      <td>LES AIX</td>\n",
       "      <td>47.216667</td>\n",
       "      <td>2.55</td>\n",
       "      <td>182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.106477</td>\n",
       "      <td>1</td>\n",
       "      <td>1950</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18003002</td>\n",
       "      <td>LES AIX</td>\n",
       "      <td>47.216667</td>\n",
       "      <td>2.55</td>\n",
       "      <td>182</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-3.019302</td>\n",
       "      <td>2</td>\n",
       "      <td>1950</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18003002</td>\n",
       "      <td>LES AIX</td>\n",
       "      <td>47.216667</td>\n",
       "      <td>2.55</td>\n",
       "      <td>182</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.601141</td>\n",
       "      <td>3</td>\n",
       "      <td>1950</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18003002</td>\n",
       "      <td>LES AIX</td>\n",
       "      <td>47.216667</td>\n",
       "      <td>2.55</td>\n",
       "      <td>182</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.346058</td>\n",
       "      <td>4</td>\n",
       "      <td>1950</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18003002</td>\n",
       "      <td>LES AIX</td>\n",
       "      <td>47.216667</td>\n",
       "      <td>2.55</td>\n",
       "      <td>182</td>\n",
       "      <td>1.9</td>\n",
       "      <td>7.248367</td>\n",
       "      <td>5</td>\n",
       "      <td>1950</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NUM_POSTE NOM_USUEL        LAT   LON  ALTI   RR     TNTXM  day_of_year  \\\n",
       "0   18003002   LES AIX  47.216667  2.55   182  0.0 -1.106477            1   \n",
       "1   18003002   LES AIX  47.216667  2.55   182  1.6 -3.019302            2   \n",
       "2   18003002   LES AIX  47.216667  2.55   182  5.4  3.601141            3   \n",
       "3   18003002   LES AIX  47.216667  2.55   182  2.0  7.346058            4   \n",
       "4   18003002   LES AIX  47.216667  2.55   182  1.9  7.248367            5   \n",
       "\n",
       "   year  is_imputed  \n",
       "0  1950        True  \n",
       "1  1950        True  \n",
       "2  1950        True  \n",
       "3  1950        True  \n",
       "4  1950        True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5887e3fb",
   "metadata": {},
   "source": [
    "#### N'utilisons qu'une portion des stations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "749b7b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "NOM_USUEL",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "328c9ffe-3708-4229-81ac-e8a85ec6209f",
       "rows": [
        [
         "AIGURANDE",
         "26663"
        ],
        [
         "ALLAINES",
         "2525"
        ],
        [
         "AMBOISE",
         "21610"
        ],
        [
         "AMBOISE - LYCEE",
         "10852"
        ],
        [
         "AMILLY",
         "21367"
        ],
        [
         "APREMONT",
         "1400"
        ],
        [
         "ARDENTES",
         "26075"
        ],
        [
         "ARDENTES - ONF",
         "8402"
        ],
        [
         "AREINES",
         "10135"
        ],
        [
         "AREINES - LYCEE",
         "2038"
        ],
        [
         "ARGENT",
         "5113"
        ],
        [
         "ARGENTON",
         "18192"
        ],
        [
         "ARTENAY SUCRERIE",
         "578"
        ],
        [
         "AUBIGNY",
         "21000"
        ],
        [
         "AUBIGNY-SUR-NERE",
         "11893"
        ],
        [
         "AUTHON",
         "26666"
        ],
        [
         "AUTRECHE",
         "3564"
        ],
        [
         "AVON-LES-ROCHES",
         "19167"
        ],
        [
         "AVORD",
         "27028"
        ],
        [
         "BACCON",
         "17289"
        ],
        [
         "BAUGY",
         "26722"
        ],
        [
         "BAULE",
         "20182"
        ],
        [
         "BAULE - LE VAL",
         "121"
        ],
        [
         "BEAUMONT_SAPC",
         "11688"
        ],
        [
         "BEAUNE-LA-ROL.",
         "15005"
        ],
        [
         "BEAUNE-MARCILLY",
         "6940"
        ],
        [
         "BEFFES",
         "1400"
        ],
        [
         "BELABRE",
         "24500"
        ],
        [
         "BENGY",
         "638"
        ],
        [
         "BETZ-LE-CHATEAU",
         "366"
        ],
        [
         "BILLANCELLES",
         "6148"
        ],
        [
         "BLANC-ARCI",
         "6267"
        ],
        [
         "BLANCAFORT",
         "12299"
        ],
        [
         "BLANDAINVILLE",
         "9357"
        ],
        [
         "BLERE",
         "4688"
        ],
        [
         "BLOIS",
         "12359"
        ],
        [
         "BLOIS - SUD",
         "1370"
        ],
        [
         "BLOIS - VILLE",
         "26972"
        ],
        [
         "BOESSE",
         "1339"
        ],
        [
         "BOISCOMMUN",
         "9496"
        ],
        [
         "BOISVILLE",
         "5905"
        ],
        [
         "BONNEVAL",
         "26267"
        ],
        [
         "BONNY-SUR-L.",
         "4353"
        ],
        [
         "BONNY-SUR-LOIRE",
         "15706"
        ],
        [
         "BOURGES",
         "28124"
        ],
        [
         "BOURGUEIL",
         "25171"
        ],
        [
         "BOUSSAY",
         "8676"
        ],
        [
         "BRECHES",
         "183"
        ],
        [
         "BRINAY",
         "13789"
        ],
        [
         "BRINON",
         "26847"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 462
       }
      },
      "text/plain": [
       "NOM_USUEL\n",
       "AIGURANDE                26663\n",
       "ALLAINES                  2525\n",
       "AMBOISE                  21610\n",
       "AMBOISE - LYCEE          10852\n",
       "AMILLY                   21367\n",
       "                         ...  \n",
       "VILLEMURLIN-PEUPLIERS    21488\n",
       "VILLENY                  26936\n",
       "VOUVRAY                   6661\n",
       "VOVES                    16313\n",
       "YZEURES/CREUSE            2306\n",
       "Name: count, Length: 462, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.NOM_USUEL.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a04b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[data['NOM_USUEL'].str.startswith(('A', 'B', 'C'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "845b0c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "84c580cb-3e92-4166-afba-7a9df357d4b7",
       "rows": [
        [
         "NUM_POSTE",
         "1619497"
        ],
        [
         "NOM_USUEL",
         "1619497"
        ],
        [
         "LAT",
         "1619497"
        ],
        [
         "LON",
         "1619497"
        ],
        [
         "ALTI",
         "1619497"
        ],
        [
         "RR",
         "1619133"
        ],
        [
         "TNTXM",
         "1619497"
        ],
        [
         "day_of_year",
         "1619497"
        ],
        [
         "year",
         "1619497"
        ],
        [
         "is_imputed",
         "1619497"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "NUM_POSTE      1619497\n",
       "NOM_USUEL      1619497\n",
       "LAT            1619497\n",
       "LON            1619497\n",
       "ALTI           1619497\n",
       "RR             1619133\n",
       "TNTXM          1619497\n",
       "day_of_year    1619497\n",
       "year           1619497\n",
       "is_imputed     1619497\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124ed4f",
   "metadata": {},
   "source": [
    "### 3.2. Marginal Modeling :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63a38d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginalPrecipitationModel:\n",
    "    \"\"\"\n",
    "    Modèle marginal en trois étapes pour les précipitations extrêmes\n",
    "    basé sur Zhong et al. (2025)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, threshold_prob=0.9):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : DataFrame\n",
    "            Données avec colonnes: RR, TNTXM, day_of_year, year, LAT, LON, ALTI, NUM_POSTE\n",
    "        threshold_prob : float\n",
    "            Probabilité de seuil pour la distribution Gamma (défaut: 0.9)\n",
    "        \"\"\"\n",
    "        self.df = df.copy()\n",
    "        self.threshold_prob = threshold_prob\n",
    "        \n",
    "        # Préparer les données (enlever les valeurs manquantes et extrêmes)\n",
    "        self.df_valid = self.df[\n",
    "            (self.df['RR'].notna()) & \n",
    "            (self.df['RR'] > 0) & \n",
    "            (self.df['RR'] < 1000)\n",
    "        ].copy()\n",
    "        \n",
    "        # Normaliser l'altitude en km\n",
    "        self.df_valid['ALTI_km'] = self.df_valid['ALTI'] / 1000\n",
    "        \n",
    "        # Résultats des modèles\n",
    "        self.gamma_model = None\n",
    "        self.binomial_model = None\n",
    "        self.gpd_params = None\n",
    "        \n",
    "    def fit_gamma_bulk(self, k_day=10, k_spatial=10, k_alti=10):\n",
    "        \"\"\"\n",
    "        Étape 1: Ajuster une distribution Gamma pour la masse de la distribution\n",
    "        \n",
    "        Modèle: RR ~ TNTXM + s(day_of_year) + te(LON, LAT) + s(ALTI)\n",
    "        \"\"\"\n",
    "        print(\"Étape 1: Ajustement du modèle Gamma...\")\n",
    "        \n",
    "        # Préparer les splines\n",
    "        x_spline_day = BSplines(\n",
    "            self.df_valid['day_of_year'], \n",
    "            df=[k_day], \n",
    "            degree=[3]\n",
    "        )\n",
    "        \n",
    "        x_spline_alti = BSplines(\n",
    "            self.df_valid['ALTI_km'], \n",
    "            df=[k_alti], \n",
    "            degree=[3]\n",
    "        )\n",
    "        \n",
    "        # Pour le terme spatial te(LON, LAT), on utilise des splines tensorielle\n",
    "        # Approximation avec produit de splines univariées\n",
    "        x_spline_lon = BSplines(\n",
    "            self.df_valid['LON'], \n",
    "            df=[k_spatial], \n",
    "            degree=[3]\n",
    "        )\n",
    "        \n",
    "        x_spline_lat = BSplines(\n",
    "            self.df_valid['LAT'], \n",
    "            df=[k_spatial], \n",
    "            degree=[3]\n",
    "        )\n",
    "        \n",
    "        # Créer la matrice de design\n",
    "        import statsmodels.api as sm\n",
    "        \n",
    "        # Modèle linéaire pour la température\n",
    "        X_temp = sm.add_constant(self.df_valid['TNTXM'])\n",
    "        \n",
    "        # Combiner avec les splines\n",
    "        X_full = np.column_stack([\n",
    "            X_temp,\n",
    "            x_spline_day.basis,\n",
    "            x_spline_lon.basis,\n",
    "            x_spline_lat.basis,\n",
    "            x_spline_alti.basis\n",
    "        ])\n",
    "        \n",
    "        # Ajuster le modèle Gamma avec lien log\n",
    "        self.gamma_model = sm.GLM(\n",
    "            self.df_valid['RR'], \n",
    "            X_full,\n",
    "            family=sm.families.Gamma(link=sm.families.links.log())\n",
    "        ).fit()\n",
    "        \n",
    "        # Prédictions\n",
    "        fitted_mean = self.gamma_model.fittedvalues\n",
    "        \n",
    "        # Estimer les paramètres de la Gamma\n",
    "        # Pour Gamma: E[Y] = shape * scale, Var[Y] = shape * scale^2\n",
    "        # Donc: shape = E[Y]^2 / Var[Y], scale = Var[Y] / E[Y]\n",
    "        residuals = self.df_valid['RR'] - fitted_mean\n",
    "        \n",
    "        # Utiliser la déviance pour estimer le paramètre de dispersion\n",
    "        scale_est = self.gamma_model.scale\n",
    "        shape_est = 1 / scale_est\n",
    "        scale_param = fitted_mean / shape_est\n",
    "        \n",
    "        # Calculer les quantiles à 90%\n",
    "        self.df_valid['gamma_shape'] = shape_est\n",
    "        self.df_valid['gamma_scale'] = scale_param\n",
    "        self.df_valid['threshold'] = stats.gamma.ppf(\n",
    "            self.threshold_prob, \n",
    "            a=shape_est, \n",
    "            scale=scale_param\n",
    "        )\n",
    "        \n",
    "        print(f\"  Paramètre de forme moyen: {shape_est:.4f}\")\n",
    "        print(f\"  Seuil moyen (90%): {self.df_valid['threshold'].mean():.2f} mm\")\n",
    "        \n",
    "        return self.gamma_model\n",
    "    \n",
    "    def fit_binomial_exceedance(self, k_day=10, k_spatial=10, k_alti=10):\n",
    "        \"\"\"\n",
    "        Étape 2: Ajuster un modèle binomial pour les dépassements de seuil\n",
    "        \n",
    "        Modèle: I(RR > threshold) ~ TNTXM + s(day_of_year) + te(LON, LAT) + s(ALTI)\n",
    "        \"\"\"\n",
    "        print(\"\\nÉtape 2: Ajustement du modèle binomial...\")\n",
    "        \n",
    "        # Créer la variable binaire\n",
    "        self.df_valid['exceeds_threshold'] = (\n",
    "            self.df_valid['RR'] > self.df_valid['threshold']\n",
    "        ).astype(int)\n",
    "        \n",
    "        # Préparer les splines (même structure que Gamma)\n",
    "        x_spline_day = BSplines(\n",
    "            self.df_valid['day_of_year'], \n",
    "            df=[k_day], \n",
    "            degree=[3]\n",
    "        )\n",
    "        \n",
    "        x_spline_alti = BSplines(\n",
    "            self.df_valid['ALTI_km'], \n",
    "            df=[k_alti], \n",
    "            degree=[3]\n",
    "        )\n",
    "        \n",
    "        x_spline_lon = BSplines(\n",
    "            self.df_valid['LON'], \n",
    "            df=[k_spatial], \n",
    "            degree=[3]\n",
    "        )\n",
    "        \n",
    "        x_spline_lat = BSplines(\n",
    "            self.df_valid['LAT'], \n",
    "            df=[k_spatial], \n",
    "            degree=[3]\n",
    "        )\n",
    "        \n",
    "        import statsmodels.api as sm\n",
    "        X_temp = sm.add_constant(self.df_valid['TNTXM'])\n",
    "        \n",
    "        X_full = np.column_stack([\n",
    "            X_temp,\n",
    "            x_spline_day.basis,\n",
    "            x_spline_lon.basis,\n",
    "            x_spline_lat.basis,\n",
    "            x_spline_alti.basis\n",
    "        ])\n",
    "        \n",
    "        # Ajuster le modèle binomial avec lien logit\n",
    "        self.binomial_model = sm.GLM(\n",
    "            self.df_valid['exceeds_threshold'],\n",
    "            X_full,\n",
    "            family=sm.families.Binomial()\n",
    "        ).fit()\n",
    "        \n",
    "        self.df_valid['exceedance_prob'] = self.binomial_model.fittedvalues\n",
    "        \n",
    "        n_exceedances = self.df_valid['exceeds_threshold'].sum()\n",
    "        print(f\"  Nombre de dépassements: {n_exceedances}\")\n",
    "        print(f\"  Probabilité moyenne de dépassement: {self.df_valid['exceedance_prob'].mean():.4f}\")\n",
    "        \n",
    "        return self.binomial_model\n",
    "    \n",
    "    def fit_gpd_tail(self, k_day=10, k_spatial=10, k_alti=10):\n",
    "        \"\"\"\n",
    "        Étape 3: Ajuster une distribution de Pareto généralisée (GPD) \n",
    "        pour les excès au-dessus du seuil\n",
    "        \n",
    "        Modèle: \n",
    "        - log(scale) ~ log(threshold) + TNTXM + s(day_of_year) + te(LON, LAT) + s(ALTI)\n",
    "        - shape: constant\n",
    "        \"\"\"\n",
    "        print(\"\\nÉtape 3: Ajustement du modèle GPD...\")\n",
    "        \n",
    "        # Sélectionner uniquement les excès\n",
    "        df_exceedances = self.df_valid[\n",
    "            self.df_valid['exceeds_threshold'] == 1\n",
    "        ].copy()\n",
    "        \n",
    "        # Calculer les excès\n",
    "        df_exceedances['excess'] = (\n",
    "            df_exceedances['RR'] - df_exceedances['threshold']\n",
    "        )\n",
    "        \n",
    "        # Vérifier qu'on a des excès positifs\n",
    "        df_exceedances = df_exceedances[df_exceedances['excess'] > 1e-5].copy()\n",
    "        \n",
    "        print(f\"  Nombre d'excès: {len(df_exceedances)}\")\n",
    "        \n",
    "        # Préparer les covariables\n",
    "        x_spline_day = BSplines(\n",
    "            df_exceedances['day_of_year'], \n",
    "            df=[k_day], \n",
    "            degree=[3]\n",
    "        )\n",
    "        \n",
    "        x_spline_alti = BSplines(\n",
    "            df_exceedances['ALTI_km'], \n",
    "            df=[k_alti], \n",
    "            degree=[3]\n",
    "        )\n",
    "        \n",
    "        x_spline_lon = BSplines(\n",
    "            df_exceedances['LON'], \n",
    "            df=[k_spatial], \n",
    "            degree=[3]\n",
    "        )\n",
    "        \n",
    "        x_spline_lat = BSplines(\n",
    "            df_exceedances['LAT'], \n",
    "            df=[k_spatial], \n",
    "            degree=[3]\n",
    "        )\n",
    "        \n",
    "        import statsmodels.api as sm\n",
    "        \n",
    "        # Inclure log(threshold) comme offset/variable\n",
    "        X_predictors = np.column_stack([\n",
    "            np.ones(len(df_exceedances)),  # Intercept\n",
    "            np.log(df_exceedances['threshold']),\n",
    "            df_exceedances['TNTXM'],\n",
    "            x_spline_day.basis[:, 1:],\n",
    "            x_spline_lon.basis[:, 1:],\n",
    "            x_spline_lat.basis[:, 1:],\n",
    "            x_spline_alti.basis[:, 1:]\n",
    "        ])\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_predictors[:, 1:] = scaler.fit_transform(X_predictors[:, 1:])\n",
    "\n",
    "        cond_number = np.linalg.cond(X_predictors)\n",
    "        print(f\"Condition number de la matrice X: {cond_number:.2e}\")\n",
    "        if cond_number > 1e10:\n",
    "            print(\"ATTENTION: Matrice mal conditionnée (colinéarité). L'optimisation va échouer.\")\n",
    "\n",
    "        # Pour la GPD, on utilise une approche de maximum de vraisemblance\n",
    "        # On modélise log(scale) avec GLM Gamma\n",
    "        \n",
    "        def gpd_neg_loglik(params, y, X):\n",
    "            \"\"\"Negative log-likelihood for GPD\"\"\"\n",
    "            n_beta = X.shape[1]\n",
    "            beta = params[:n_beta]\n",
    "            xi = params[n_beta]  # shape parameter\n",
    "            \n",
    "            log_scale = X @ beta\n",
    "            scale = np.exp(log_scale)\n",
    "            \n",
    "            # GPD log-likelihood\n",
    "            if abs(xi) < 1e-5:\n",
    "            # Cas exponentiel (limite xi -> 0)\n",
    "                ll = -np.sum(np.log(scale)) - np.sum(y / scale)\n",
    "            else:\n",
    "                z = 1 + xi * y / scale\n",
    "                if np.any(z <= 0):\n",
    "                    return 1e12\n",
    "            \n",
    "            # Log-vraisemblance standard\n",
    "            ll = -np.sum(np.log(scale)) - (1/xi + 1) * np.sum(np.log(z))\n",
    "\n",
    "            return -ll\n",
    "        \n",
    "        # Initialisation\n",
    "        initial_beta = np.zeros(X_predictors.shape[1])\n",
    "        initial_beta[0] = np.log(df_exceedances['excess'].mean())\n",
    "        initial_xi = 0.1\n",
    "        initial_params = np.concatenate([initial_beta, [initial_xi]])\n",
    "        \n",
    "        bounds = [(None, None)] * X_predictors.shape[1] + [(-0.5, 0.8)]\n",
    "\n",
    "        # Optimisation\n",
    "        result = minimize(\n",
    "            gpd_neg_loglik,\n",
    "            initial_params,\n",
    "            args=(df_exceedances['excess'].values, X_predictors),\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds,\n",
    "            options={'maxiter': 5000, 'xatol': 1e-4, 'fatol': 1e-4}\n",
    "        )\n",
    "        \n",
    "        if result.success:\n",
    "            beta_hat = result.x[:-1]\n",
    "            xi_hat = result.x[-1]\n",
    "            \n",
    "            self.gpd_params = {\n",
    "                'beta': beta_hat,\n",
    "                'xi': xi_hat,\n",
    "                'X_predictors': X_predictors\n",
    "            }\n",
    "            \n",
    "            # Calculer les échelles ajustées\n",
    "            log_scale_fitted = X_predictors @ beta_hat\n",
    "            df_exceedances['gpd_scale'] = np.exp(log_scale_fitted)\n",
    "            df_exceedances['gpd_shape'] = xi_hat\n",
    "            \n",
    "            print(f\"  Paramètre de forme ξ: {xi_hat:.4f}\")\n",
    "            print(f\"  Échelle moyenne: {df_exceedances['gpd_scale'].mean():.2f}\")\n",
    "            \n",
    "            # Stocker les résultats\n",
    "            self.df_exceedances = df_exceedances\n",
    "        else:\n",
    "            print(\"  ATTENTION: L'optimisation GPD n'a pas convergé\")\n",
    "            self.gpd_params = None\n",
    "        \n",
    "        return self.gpd_params\n",
    "    \n",
    "    def transform_to_uniform(self):\n",
    "        \"\"\"\n",
    "        Transformer les données vers une échelle uniforme [0,1]\n",
    "        en utilisant la transformation intégrale de probabilité.\n",
    "        Version corrigée : utilise pd.Series indexée pour éviter IndexError.\n",
    "        \"\"\"\n",
    "        print(\"\\nTransformation vers échelle uniforme...\")\n",
    "\n",
    "        # Créer une Series indexée comme self.df_valid\n",
    "        uniform_scores = pd.Series(index=self.df_valid.index, dtype=float)\n",
    "\n",
    "        # Indices non-excédants\n",
    "        non_exceed_idx = self.df_valid['exceeds_threshold'] == 0\n",
    "        if non_exceed_idx.any():\n",
    "            # stats.gamma.cdf peut accepter tableaux alignés\n",
    "            uniform_scores.loc[non_exceed_idx] = stats.gamma.cdf(\n",
    "                self.df_valid.loc[non_exceed_idx, 'RR'].values,\n",
    "                a=self.df_valid.loc[non_exceed_idx, 'gamma_shape'].values,\n",
    "                scale=self.df_valid.loc[non_exceed_idx, 'gamma_scale'].values\n",
    "            )\n",
    "\n",
    "        # Pour les excédants (si GPD ajusté)\n",
    "        if self.gpd_params is not None and hasattr(self, 'df_exceedances'):\n",
    "            exceed_idx = self.df_valid['exceeds_threshold'] == 1\n",
    "            if exceed_idx.any():\n",
    "                # Probabilité d'excéder le seuil pour ces observations\n",
    "                exceed_prob = self.df_valid.loc[exceed_idx, 'exceedance_prob']\n",
    "\n",
    "                # On utilise df_exceedances (index commun) pour récupérer scale et xi\n",
    "                # itération sur df_exceedances est sûre car ses index appartiennent à self.df_valid.index\n",
    "                for orig_idx, row_exc in self.df_exceedances.iterrows():\n",
    "                    # excess = observed - threshold (déjà calculé dans df_exceedances)\n",
    "                    excess = row_exc['excess']\n",
    "                    scale = row_exc['gpd_scale']\n",
    "                    xi = row_exc['gpd_shape']\n",
    "\n",
    "                    # CDF de la GPD conditionnelle P(Y <= y | Y > u)\n",
    "                    if abs(xi) < 1e-6:\n",
    "                        p_excess = 1 - np.exp(-excess / scale)\n",
    "                    else:\n",
    "                        z = 1 + xi * excess / scale\n",
    "                        if z > 0:\n",
    "                            p_excess = 1 - z ** (-1.0 / xi)\n",
    "                        else:\n",
    "                            p_excess = 1.0\n",
    "\n",
    "                    # Probabilité totale: P(Y <= y) = (1 - p_u) + p_u * P_cond\n",
    "                    pu = exceed_prob.loc[orig_idx]\n",
    "                    uniform_scores.loc[orig_idx] = (1.0 - pu) + pu * p_excess\n",
    "\n",
    "        # Remplir les éventuels NaN restants à sécurité (par ex. si aucune catégorie)\n",
    "        uniform_scores = uniform_scores.fillna(0.0)\n",
    "\n",
    "        # Empêcher la valeur exactement égale à 1.0\n",
    "        self.df_valid['uniform_score'] = (uniform_scores / (1.0 + 1e-10)).astype(float)\n",
    "\n",
    "        print(f\"  Scores uniformes calculés pour {self.df_valid['uniform_score'].notna().sum()} observations\")\n",
    "\n",
    "        return self.df_valid['uniform_score']\n",
    "\n",
    "    \n",
    "    def transform_to_unit_pareto(self):\n",
    "        \"\"\"\n",
    "        Transformer vers échelle Pareto unitaire pour l'analyse de dépendance\n",
    "        \"\"\"\n",
    "        if 'uniform_score' not in self.df_valid.columns:\n",
    "            self.transform_to_uniform()\n",
    "        \n",
    "        # Transformation: Y_pareto = 1 / (1 - U)\n",
    "        # où U ~ Uniform(0,1)\n",
    "        unit_pareto = 1 / (1 - self.df_valid['uniform_score'])\n",
    "        self.df_valid['unit_pareto'] = unit_pareto\n",
    "        \n",
    "        print(f\"\\nTransformation Pareto unitaire:\")\n",
    "        print(f\"  Min: {unit_pareto.min():.2f}\")\n",
    "        print(f\"  Max: {unit_pareto.max():.2f}\")\n",
    "        print(f\"  Médiane: {unit_pareto.median():.2f}\")\n",
    "        \n",
    "        return unit_pareto\n",
    "    \n",
    "    def fit_complete_model(self):\n",
    "        \"\"\"\n",
    "        Ajuster le modèle complet en trois étapes\n",
    "        \"\"\"\n",
    "        self.fit_gamma_bulk()\n",
    "        self.fit_binomial_exceedance()\n",
    "        self.fit_gpd_tail()\n",
    "        self.transform_to_uniform()\n",
    "        self.transform_to_unit_pareto()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_results_summary(self):\n",
    "        \"\"\"\n",
    "        Obtenir un résumé des résultats\n",
    "        \"\"\"\n",
    "        summary = {\n",
    "            'n_observations': len(self.df_valid),\n",
    "            'n_exceedances': self.df_valid['exceeds_threshold'].sum(),\n",
    "            'threshold_90pct': self.df_valid['threshold'].mean(),\n",
    "            'gamma_shape': self.df_valid['gamma_shape'].mean(),\n",
    "            'exceedance_prob': self.df_valid['exceedance_prob'].mean(),\n",
    "        }\n",
    "        \n",
    "        if self.gpd_params is not None:\n",
    "            summary['gpd_shape'] = self.gpd_params['xi']\n",
    "            summary['gpd_scale_mean'] = self.df_exceedances['gpd_scale'].mean()\n",
    "        \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2237caf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Étape 1: Ajustement du modèle Gamma...\n",
      "  Paramètre de forme moyen: 0.6685\n",
      "  Seuil moyen (90%): 11.46 mm\n",
      "\n",
      "Étape 2: Ajustement du modèle binomial...\n",
      "  Nombre de dépassements: 68891\n",
      "  Probabilité moyenne de dépassement: 0.0975\n",
      "\n",
      "Étape 3: Ajustement du modèle GPD...\n",
      "  Nombre d'excès: 68891\n",
      "Condition number de la matrice X: 2.27e+01\n",
      "  Paramètre de forme ξ: 0.0370\n",
      "  Échelle moyenne: 6.02\n",
      "\n",
      "Transformation vers échelle uniforme...\n",
      "  Scores uniformes calculés pour 706454 observations\n",
      "\n",
      "Transformation Pareto unitaire:\n",
      "  Min: 1.04\n",
      "  Max: 4796810.74\n",
      "  Médiane: 2.01\n",
      "\n",
      "Résumé des résultats:\n",
      "  n_observations: 706454\n",
      "  n_exceedances: 68891\n",
      "  threshold_90pct: 11.460000930116331\n",
      "  gamma_shape: 0.6685482901542256\n",
      "  exceedance_prob: 0.0975166111310887\n",
      "  gpd_shape: 0.03695875743213462\n",
      "  gpd_scale_mean: 6.023142051712279\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    model = MarginalPrecipitationModel(df, threshold_prob=0.9)\n",
    "    model.fit_complete_model()\n",
    "    \n",
    "    # Obtenir les résultats\n",
    "    summary = model.get_results_summary()\n",
    "    print(\"\\nRésumé des résultats:\")\n",
    "    for key, value in summary.items():\n",
    "         print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Les données transformées sont dans model.df_valid\n",
    "    # avec les colonnes 'uniform_score' et 'unit_pareto'\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9933391",
   "metadata": {},
   "source": [
    "### 3.3 Dependance Modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_projet_3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
